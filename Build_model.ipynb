{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from io import StringIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_tweets_char_clean.csv',names = [\"userID\",\"tweets\"])\n",
    "df = df[pd.notnull(df['tweets'])]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['userID', 'tweets']\n",
    "df = df[col]\n",
    "df.columns = ['userID', 'tweets']\n",
    "df['category_id'] = df['userID'].factorize()[0]\n",
    "category_id_df = df[['userID', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'userID']].values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Settings\n",
    "tfidf = TfidfVectorizer(analyzer='char', stop_words='english',use_idf=True,max_features=137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# X_train = df['tweets']\n",
    "# y_train = df['userID']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['tweets'], df['userID'], test_size=0.1, random_state=2)\n",
    "\n",
    "# tfidf.fit(df['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xtrain_tfidf =  tfidf.fit_transform(X_train)\n",
    "xtest_tfidf = tfidf.fit_transform(X_test)\n",
    "count_vect = CountVectorizer(analyzer='word', stop_words='english')\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(xtrain_tfidf)\n",
    "x_test_tfidf = tfidf_transformer.fit_transform(xtest_tfidf)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (xtrain_tfidf.shape, xtest_tfidf.shape)\n",
    "print (x_train_tfidf.shape, x_test_tfidf.shape)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Liner Model Logistic Regression\n",
    "clf = LinearSVC(penalty=\"l2\",class_weight='balanced',random_state=1).fit(x_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test_tfidf,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Nearest Neighbors\n",
    "clf = NearestCentroid(metric='manhattan')\n",
    "clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#MLP Classifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#SVM\n",
    "clf = NuSVC(nu=0.5, kernel='rbf', degree=3, gamma='auto_deprecated', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Linear Perceptron\n",
    "clf = Perceptron()\n",
    "clf.fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(clf.predict(tfidf.transform([\"RT @handle: Director of Global Brand Marketing, Hotels and Casino's $125k + 30% bonus - Orlando Fl http://bit.ly/4kUmBB #jobs #twitjobs\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_tweet_text(tweet):\n",
    "    text = re.sub(r'@\\w+\\s?', '', tweet)\n",
    "    text = re.sub(r'http.?://[^\\s]+[\\s]?', '', text)\n",
    "    text = re.sub('#\\w+\\s?', '', text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only link pre processing\n",
    "import re\n",
    "def clean_tweet_text(tweet):\n",
    "    text = re.sub(r'http.?://[^\\s]+[\\s]?', 'http-web-link', tweet)\n",
    "    print (text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "line_num = 1\n",
    "with open('./whodunnit/test_tweets_unlabeled.txt') as un_fd:\n",
    "    with open('result_lin_svc_tfidf_full_wpp.txt','w') as res:\n",
    "        for line in un_fd.readlines():\n",
    "            clean_line = clean_tweet_text(line)\n",
    "            userID = clf.predict(tfidf.transform([clean_line])).tolist()\n",
    "            print (userID)\n",
    "            res.write(\"%s\\t%s\\n\"%(line_num,userID[0]))\n",
    "            line_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ((xtrain_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
